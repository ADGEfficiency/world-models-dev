{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Memory using a toy problem\n",
    "\n",
    "Problem and inspiration from the excellent [Mixture Density Networks with TensorFlow](http://blog.otoro.net/2015/11/24/mixture-density-networks-with-tensorflow/).\n",
    "\n",
    "This notebook was used during development, and can be run to prove the quality of both the Gaussian Mixture and the LSTM.\n",
    "\n",
    "## Gaussian mixture with a fully connected head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from worldmodels.memory.memory import GaussianMixture, MLP, Memory\n",
    "from worldmodels.memory.memory import get_pi_idx\n",
    "from worldmodels.memory.train_memory import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "NSAMPLE = 5000\n",
    "\n",
    "y_data = np.random.uniform(-10.5, 10.5, (1, NSAMPLE)).T\n",
    "r_data = np.random.normal(size=(NSAMPLE,1))\n",
    "x_data = np.sin(0.75*y_data)*7.0+y_data*0.5+r_data*1.0\n",
    "\n",
    "num_timesteps = 1\n",
    "num_features = 1\n",
    "num_mix = 24\n",
    "batch_size = NSAMPLE\n",
    "\n",
    "y_data = y_data.reshape(NSAMPLE, num_timesteps, num_features).astype(np.float32)\n",
    "x_data = x_data.reshape(NSAMPLE, num_timesteps, num_features).astype(np.float32)\n",
    "\n",
    "#  this will be the shape of the output of the lstm\n",
    "#  (batch_size, num_timesteps, output_dim * num_mix * 3)\n",
    "#Â  three for one pi, mu, sigma for each mixture\n",
    "mixture_dim = num_features * num_mix * 3\n",
    "print(mixture_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MLP(num_mix, hidden_nodes=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = GaussianMixture(num_features, num_mix, num_timesteps=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample = x_data[0:2]\n",
    "x_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi, mu, sigma = mixture(memory(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-8.537479]],\n",
       "\n",
       "       [[-5.747335]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-8.953089 ]],\n",
       "\n",
       "       [[-3.2859719]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5.855290412902832\n",
      "501 2.820934295654297\n",
      "1001 2.5898289680480957\n"
     ]
    }
   ],
   "source": [
    "def train_op(memory, mixture, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = mixture.get_loss(memory(x), y)\n",
    "        gradients = tape.gradient(loss, memory.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, memory.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)).shuffle(NSAMPLE).batch(batch_size)\n",
    "epochs = 5000\n",
    "loss = np.zeros(epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataset:\n",
    "        loss[epoch] = train_op(memory, mixture, *batch)\n",
    "    if epoch % 500 == 1:\n",
    "        print(epoch, loss[epoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(np.arange(epochs), loss[:epochs], 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.float32(np.arange(-15,15,0.1))\n",
    "n_test = x_test.shape[0]\n",
    "x_test = x_test.reshape(n_test, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus, sigmas, idxs = np.zeros(n_test), np.zeros(n_test), np.zeros(n_test)\n",
    "samples = np.zeros(n_test)\n",
    "\n",
    "for num, sample in enumerate(x_test):\n",
    "    pi, mu, sigma = mixture(memory(sample.reshape(1, 1, 1)))\n",
    "    \n",
    "    pi = np.array(pi).reshape(1, pi.shape[3])\n",
    "    mu = np.array(mu).reshape(1, mu.shape[3])\n",
    "    sigma = np.array(sigma).reshape(1, sigma.shape[3])\n",
    "\n",
    "    idx = get_pi_idx(pi[0], None)\n",
    "    \n",
    "    idxs[num] = idx\n",
    "    mus[num] = mu[:, idx]\n",
    "    sigmas[num] = sigma[:, idx]\n",
    "    \n",
    "    samples[num] = mus[num] + np.random.randn() * sigmas[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(np.squeeze(x_data),np.squeeze(y_data), 'ro', np.squeeze(x_test), np.squeeze(samples), 'bo', alpha=0.3)\n",
    "\n",
    "plt.ylim(-10, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian mixture with an LSTM head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldmodels = Memory(\n",
    "    input_dim=1, \n",
    "    output_dim=num_features, \n",
    "    num_timesteps=num_timesteps, \n",
    "    batch_size=batch_size, \n",
    "    lstm_nodes=24, \n",
    "    num_mix=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_data\n",
    "y = y_data\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(x.shape[0]).batch(batch_size)\n",
    "\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataset:\n",
    "        state = worldmodels.lstm.get_zero_hidden_state(x)\n",
    "        loss[epoch] = worldmodels.train_op(*batch, state)\n",
    "    if epoch % 500 == 1:\n",
    "        print(epoch, loss[epoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(np.arange(epochs), loss[:epochs], 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.reshape(1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus, sigmas, idxs = np.zeros(n_test), np.zeros(n_test), np.zeros(n_test)\n",
    "\n",
    "samples = np.zeros(n_test)\n",
    "\n",
    "for num, sample in enumerate(x_test):\n",
    "\n",
    "    latent, _, _ = world_models.lstm.net(sample.reshape(1, 1, 1))\n",
    "    \n",
    "    pi, mu, sigma = world_models.mixture(latent)\n",
    "    \n",
    "    idx = get_pi_idx(pi)\n",
    "    \n",
    "    idxs[num] = idx\n",
    "    mus[num] = mu[:, :, idx]\n",
    "    sigmas[num] = sigma[:, :, idx]\n",
    "    \n",
    "    samples[num] = mus[num] + np.random.randn() * sigmas[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(np.squeeze(x_data),np.squeeze(y_data), 'ro', np.squeeze(x_test), np.squeeze(samples), 'bo', alpha=0.3)\n",
    "\n",
    "plt.ylim(-10, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
