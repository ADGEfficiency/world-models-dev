Berlin photos, post onto medium, mentorcruise

## Table of contents

## Motivations

Like the paper, love the blog post

Learn inside a dream

Open AI challenge

show final code in all the sections

## Timeline

### April

VAE (loss balancing, error on resize), tensorflow beta, tests

6 - start

11 - latent stats sampling

lstm hidden state (tf2 beta)

29 - mdn (nan loss, cgant fine tune, using notebook, num mixes)

### May

1 memory trainig working

13 evolution stuff!

tf.data

preloads, hard to use

### June

### July

Agent one 

7 run on memory

31 first run on controller

### November

Agent two
- resize
- cant reconstruct (exploration)
- vae poor
- memory good?

22 Agent three
- sample from controller (5000 images)
- vae train well
- memory poor

? Agent four
- vae train well
- memory still poor (20 or 40 epoch on 5000)

### December

Agent five (linus quote)
- vae well
- memory still poor (40 or 80 epoch on 5000)

| agent | VAE epochs | VAE images
|---|---|---|
|four| 15 | 5,000



## Final results

Ha quote about 850

Reproduce paper plots


## Methods

Each bash command



## AWS lessons 

S3, AMI, security groups

## AWS costs

Per component, per month

## Unfinished

DOOM, dream

## Improvements

VAE loss balancing

Num mixes?

CMA-ES sigma decay

Really need 16 generations per population?
- 
